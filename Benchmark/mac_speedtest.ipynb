{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE17Pt2xIjPf"
   },
   "source": [
    "# Testing Tensorflow on macOS and with Apple Silicon\n",
    "\n",
    "**Note:** If running this on Mac, execute it in a `tensorflow_macos` environment.\n",
    "\n",
    "To install `tensorflow_macos`, follow the installation steps in the repository: https://github.com/apple/tensorflow_macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SUYJBQ96-bkY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0q19wMGx-bka",
    "outputId": "8e7dab95-28a5-4eb7-a36d-ef7d478abeec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mlxR1wvJx7g"
   },
   "source": [
    "**Note:** The following three cells won't work on Colab, they require the `tensorflow_macos` fork of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TxVK4fuQ-bka"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.mlcompute import mlcompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tgaDAFQQ-bkb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlcompute.is_apple_mlc_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m0KDx3IP-bkb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlcompute.is_tf_compiled_with_apple_mlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lerUPH0v-bkb"
   },
   "source": [
    "# Test 1 - Basic CNN\n",
    "\n",
    "First we'll need some data (comment/uncomment the cell below if data is required/not required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pfByLU43-bkb"
   },
   "outputs": [],
   "source": [
    "# Download data (if needed)\n",
    "# Data is a subset of Food101 - https://www.kaggle.com/dansbecker/food-101\n",
    "!wget -q https://www.dropbox.com/s/hqjg1j8teqimvyx/10_food_classes_10_percent.zip\n",
    "!wget -q https://www.dropbox.com/s/7umiyjiimhqyxj0/10_food_classes_all_data.zip\n",
    "\n",
    "import zipfile\n",
    "\n",
    "def unzip_data(filename):\n",
    "  \"\"\"\n",
    "  Unzips filename into the current working directory.\n",
    "\n",
    "  Args:\n",
    "    filename (str): a filepath to a target zip folder to be unzipped.\n",
    "  \"\"\"\n",
    "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
    "  zip_ref.extractall()\n",
    "  zip_ref.close()\n",
    "\n",
    "unzip_data(\"10_food_classes_all_data.zip\")\n",
    "unzip_data(\"10_food_classes_10_percent.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LLdqqUjS-bkb"
   },
   "outputs": [],
   "source": [
    "# Smaller dataset\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\"\n",
    "\n",
    "# # Larger dataset\n",
    "# train_dir = \"10_food_classes_all_data/train\"\n",
    "# test_dir = \"10_food_classes_all_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1VBv3US-bkb",
    "outputId": "5880d560-89b3-4243-f72c-6ef18a8de40f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ice_cream',\n",
       " 'chicken_curry',\n",
       " 'steak',\n",
       " 'sushi',\n",
       " 'chicken_wings',\n",
       " 'grilled_salmon',\n",
       " 'hamburger',\n",
       " 'pizza',\n",
       " 'ramen',\n",
       " 'fried_rice']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbJlnphv-bkc",
    "outputId": "452da2f3-e241-41ef-abd3-bc6b492d5d8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 10 classes.\n",
      "Found 2500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data inputs (need batch size of ~4 for transfer learning on M1)\n",
    "IMG_SIZE = (224, 224)\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                 image_size=IMG_SIZE,\n",
    "                                                                 label_mode=\"categorical\",\n",
    "                                                                 batch_size=32)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpWP4o0U-bkc",
    "outputId": "be9ebbd0-a77d-4c3a-b708-457d7a451d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 13s 538ms/step - loss: 2.2999 - accuracy: 0.0986 - val_loss: 2.2509 - val_accuracy: 0.1364\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 12s 512ms/step - loss: 2.2061 - accuracy: 0.1818 - val_loss: 2.2404 - val_accuracy: 0.1908\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 12s 499ms/step - loss: 1.9742 - accuracy: 0.3134 - val_loss: 2.3379 - val_accuracy: 0.1656\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 12s 498ms/step - loss: 1.6772 - accuracy: 0.4392 - val_loss: 2.5653 - val_accuracy: 0.1848\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 13s 517ms/step - loss: 1.1239 - accuracy: 0.6585 - val_loss: 3.0334 - val_accuracy: 0.1684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148a05550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a simple conv net\n",
    "model = tf.keras.Sequential([\n",
    "    # Normalize pixel inputs\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    \n",
    "    # Create a basic conv net (same as https://poloclub.github.io/cnn-explainer/)\n",
    "    tf.keras.layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "model.fit(train_data,\n",
    "          epochs=5,\n",
    "          validation_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fXnnQqx-bkc"
   },
   "source": [
    "# Test 2 - Transfer Learning\n",
    "\n",
    "We need a smaller batch sizer for transfer learning on M1 chips (takes up less memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdo8P7rD-bkd",
    "outputId": "e809a07a-4ae2-482f-fa70-a9921e13a0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 10 classes.\n",
      "Found 2500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data inputs (need batch size of ~4 for transfer learning on M1)\n",
    "IMG_SIZE = (224, 224)\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                 image_size=IMG_SIZE,\n",
    "                                                                 label_mode=\"categorical\",\n",
    "                                                                 batch_size=4)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqEXrKF_-bkd",
    "outputId": "f080755c-cd8f-4491-d584-6c71cc91cb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 4s 0us/step\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 23s 112ms/step - loss: 2.2342 - accuracy: 0.1864 - val_loss: 2.0523 - val_accuracy: 0.3413\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 1.6243 - accuracy: 0.5509 - val_loss: 4.3734 - val_accuracy: 0.2500\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 1.3472 - accuracy: 0.6191 - val_loss: 1.8725 - val_accuracy: 0.3686\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 20s 106ms/step - loss: 1.1847 - accuracy: 0.6385 - val_loss: 2.0803 - val_accuracy: 0.3125\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 1.0733 - accuracy: 0.7148 - val_loss: 1.7970 - val_accuracy: 0.4343\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 1.0058 - accuracy: 0.7250 - val_loss: 1.9966 - val_accuracy: 0.2949\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.9390 - accuracy: 0.7110 - val_loss: 1.5984 - val_accuracy: 0.4856\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.9434 - accuracy: 0.7160 - val_loss: 1.8066 - val_accuracy: 0.3734\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.8684 - accuracy: 0.7490 - val_loss: 1.7807 - val_accuracy: 0.3878\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.7914 - accuracy: 0.7669 - val_loss: 2.5110 - val_accuracy: 0.3686\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 21s 109ms/step - loss: 0.8142 - accuracy: 0.7624 - val_loss: 1.9396 - val_accuracy: 0.3702\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 20s 109ms/step - loss: 0.8032 - accuracy: 0.7509 - val_loss: 1.9779 - val_accuracy: 0.3141\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 21s 110ms/step - loss: 0.7870 - accuracy: 0.7747 - val_loss: 2.1871 - val_accuracy: 0.3093\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.7495 - accuracy: 0.7626 - val_loss: 1.9669 - val_accuracy: 0.3478\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.7217 - accuracy: 0.7819 - val_loss: 1.9989 - val_accuracy: 0.3157\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 21s 111ms/step - loss: 0.6692 - accuracy: 0.8186 - val_loss: 1.9335 - val_accuracy: 0.3894\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 21s 109ms/step - loss: 0.6483 - accuracy: 0.7923 - val_loss: 2.2381 - val_accuracy: 0.2788\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 22s 115ms/step - loss: 0.6539 - accuracy: 0.8040 - val_loss: 2.2211 - val_accuracy: 0.2901\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6700 - accuracy: 0.8193 - val_loss: 2.0534 - val_accuracy: 0.3526\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.6596 - accuracy: 0.7941 - val_loss: 2.1629 - val_accuracy: 0.3558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f4d8fa0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a transfer learning model - https://arxiv.org/abs/1905.11946\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create inputs and outputs\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "model.fit(train_data,\n",
    "          epochs=20,\n",
    "          batch_size=4, # need smaller batch size for M1\n",
    "          steps_per_epoch=len(train_data),\n",
    "          validation_data=test_data,\n",
    "          validation_steps=int(0.25 * len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIqSq3dK-bke"
   },
   "source": [
    "# Test 3 - GitHub Benchmark\n",
    "\n",
    "Benchmark from GitHub: https://github.com/apple/tensorflow_macos/issues/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5pQh1DC-bke",
    "outputId": "575fe538-69ef-4c54-dba3-da13314a4af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (3.14.0)\n",
      "Requirement already satisfied: dill in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.3)\n",
      "Requirement already satisfied: six in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (20.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (4.56.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (5.1.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (0.27.0)\n",
      "Requirement already satisfied: absl-py in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (0.11.0)\n",
      "Requirement already satisfied: numpy in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (1.18.5)\n",
      "Requirement already satisfied: promise in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: termcolor in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: future in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.52.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/Users/loyio/miniforge3/envs/tf24/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The benchmark requires tensorflow_datasets (you may need to restart the kernel after this)\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQPh0xqw-bkf",
    "outputId": "a5275751-0d08-45e5-9c61-0fa7e0157f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 469 steps, validate on 79 steps\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - ETA: 0s - batch: 234.0000 - size: 1.0000 - loss: 0.6969 - accuracy: 0.8657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loyio/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.6969 - accuracy: 0.8657 - val_loss: 0.1704 - val_accuracy: 0.9644\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.1222 - accuracy: 0.9706 - val_loss: 0.1102 - val_accuracy: 0.9778\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0783 - accuracy: 0.9801 - val_loss: 0.0821 - val_accuracy: 0.9776\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0657 - accuracy: 0.9834 - val_loss: 0.0675 - val_accuracy: 0.9815\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0508 - accuracy: 0.9869 - val_loss: 0.0620 - val_accuracy: 0.9834\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 21s 44ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0436 - accuracy: 0.9887 - val_loss: 0.0564 - val_accuracy: 0.9844\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0369 - accuracy: 0.9904 - val_loss: 0.0548 - val_accuracy: 0.9837\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0637 - val_accuracy: 0.9816\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 22s 45ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0334 - accuracy: 0.9914 - val_loss: 0.0544 - val_accuracy: 0.9830\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 22s 45ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.0527 - val_accuracy: 0.9835\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 21s 43ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0223 - accuracy: 0.9948 - val_loss: 0.0571 - val_accuracy: 0.9827\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 22s 45ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0197 - accuracy: 0.9955 - val_loss: 0.0484 - val_accuracy: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1680c9460>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "mlcompute.set_mlc_device(device_name='gpu')\n",
    "\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mac-speedtest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
